{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "304a56c5",
   "metadata": {},
   "source": [
    "## Integration of a Large Language Model (LLM)\n",
    "\n",
    "To enrich the analysis and support interpretation tasks,  \n",
    "we integrated the **OpenAI GPT model** using the official Python API.\n",
    "\n",
    "The model can be used to:\n",
    "- generate explanations and summaries of results,\n",
    "- assist with code documentation and interpretation,\n",
    "- or even answer natural language queries about the dataset.\n",
    "\n",
    "The API key is securely loaded from a `.env` file to protect credentials.\n",
    "\n",
    "```python\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4436d16a",
   "metadata": {},
   "source": [
    "## OpenAI API Setup\n",
    "\n",
    "We load the OpenAI API key from a secure `.env` file using the `python-dotenv` package.  \n",
    "This allows us to query GPT models directly from the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "329ed0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key found: True\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load API key from .env file\n",
    "load_dotenv(\"../.env\")\n",
    "print(\"Key found:\", os.getenv(\"OPENAI_API_KEY\") is not None)\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0031d33",
   "metadata": {},
   "source": [
    "## Prompt Construction\n",
    "\n",
    "We create a natural language prompt based on the current DataFrame column names.  \n",
    "This prompt is sent to GPT to generate ideas for analysis and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a prompt based on the DataFrame columns\n",
    "columns = df.columns.tolist()\n",
    "prompt = f\"\"\"\n",
    "I have a DataFrame with the following columns: {columns}.\n",
    "Please suggest 3 meaningful analyses, visualizations, or statistical tests I could perform.\n",
    "Explain each briefly.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528a0c83",
   "metadata": {},
   "source": [
    "## ðŸ¤– GPT Analysis Suggestions\n",
    "\n",
    "We send the prompt to the OpenAI GPT model (`gpt-3.5-turbo`) and print its response.  \n",
    "The model suggests possible directions for analysis based on our dataset structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Genre Analysis:\n",
      "Perform an analysis to identify the most popular genres in terms of average rating and number of votes. This can be presented as a bar chart or a heatmap, showing the average rating and number of votes for each genre. This analysis can help understand audience preferences and the overall quality of content in different genres.\n",
      "\n",
      "2. Yearly Trends Analysis:\n",
      "Create a line chart or time series plot to visualize the trends in average ratings over the years. This analysis can help identify any patterns or changes in the quality of content over time. It could also identify any trends in viewer engagement based on the number of votes received each year.\n",
      "\n",
      "3. Rating vs. Votes Relationship:\n",
      "Conduct a correlation analysis between average rating and the number of votes to determine if there is any relationship between the two. Scatter plots or a correlation matrix can be used to visualize this relationship. Understanding how rating and votes are related can provide insights into viewer engagement and how ratings are influenced by the number of votes received.\n"
     ]
    }
   ],
   "source": [
    "# Query GPT-3.5 for suggestions\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful data analyst.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Display the suggestions\n",
    "print(response.choices[0].message[\"content\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
